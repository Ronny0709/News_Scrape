{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<span style=\"font-size: 36px;\">NEWS SCRAPING & KEYWORDS</span>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of this project : \n",
    "1. Scrape the news articles from webpage, organize data by normalization.\n",
    "2. Analyze the article, grasp the insight by using external tool. (Tableau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<span style=\"font-size: 26px;\">STEP 1 : SCRAPING NEWS ARTICLES (CREATING DATABASE)</span>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#response check url\n",
    "url1 = \"https://www.japantimes.co.jp/morearticles/world/?pgno=1\"\n",
    "requests.get(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#News sections to scrape\n",
    "section_list = ['japan', 'world', 'asia-pacific']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get 'article class' under class 'jt-more-articles'\n",
    "def get_html(session, section, page):\n",
    "    url1 = f\"https://www.japantimes.co.jp/morearticles/{section}/?pgno={page}\"\n",
    "    response = session.get(url1)\n",
    "    htmltext = response.text\n",
    "    orghtml = BeautifulSoup(htmltext, \"html.parser\")\n",
    "    articles = orghtml.select(\".jt-more-articles > .article\")\n",
    "    return articles\n",
    "\n",
    "\n",
    "#Remove 'and','By','\\n' and blanks from .article-byline to not remove by or and within author's name\n",
    "def clean_names(input):\n",
    "    cleaned_string = re.sub(r'\\bBy\\b', '', input, flags=re.IGNORECASE) #Remove 'By'\n",
    "    cleaned_string = re.sub(r'\\band\\b', ',', cleaned_string, flags=re.IGNORECASE) #Replace 'and' with ','\n",
    "    cleaned_string = cleaned_string.replace('\\n','')\n",
    "    cleaned_string = cleaned_string.strip()\n",
    "    return cleaned_string\n",
    "\n",
    "#get author,date,division,title,summary for each articles and clean it \n",
    "def html_seperation(article,newslist):\n",
    "    title_element = article.select_one(\".article-title > a\").text\n",
    "    division_element = article.select_one(\".article-section\").text.replace('\\n','').replace('/',',')\n",
    "    summary_element = article.select_one(\".article-body > a\").text\n",
    "    date_element = article.select_one(\".publish-date\").text\n",
    "    author_element = clean_names(article.select_one(\".article-byline\").text)\n",
    "    newslist.append([date_element,division_element,author_element,title_element,summary_element])\n",
    "\n",
    "#Change list into table and export to .csv file\n",
    "def news_scrape(section, pagelim):\n",
    "    news_data = []\n",
    "    with requests.Session() as session:\n",
    "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            futures = [executor.submit(get_html, session, section, i) for i in range(1, pagelim)]\n",
    "            for future in futures:\n",
    "                articles = future.result()\n",
    "                for article in articles:\n",
    "                    news_data.append(html_seperation(article))\n",
    "    all_df = pd.DataFrame(news_data, columns=['date', 'division', 'author', 'title', 'summary'])\n",
    "    print(f\"{section}... Success\")\n",
    "    return all_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape news articles\n",
    "\n",
    "section_dataframes = {}\n",
    "\n",
    "for section in section_list:\n",
    "    section_df = news_scrape(section, 1101)\n",
    "    section_dataframes[section] = section_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>division</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>May 26, 2024</td>\n",
       "      <td>JAPAN, Politics</td>\n",
       "      <td>Jesse Johnson</td>\n",
       "      <td>Kishida meets China's Li and South Korea's Yoo...</td>\n",
       "      <td>The Japanese leader discussed improving ties w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May 26, 2024</td>\n",
       "      <td>JAPAN, Politics</td>\n",
       "      <td></td>\n",
       "      <td>Constitutional Democratic Party executives can...</td>\n",
       "      <td>The CDP submitted a bill to the Lower House th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>May 26, 2024</td>\n",
       "      <td>JAPAN, ANALYSIS</td>\n",
       "      <td>Gabriel Dominguez</td>\n",
       "      <td>Evolving drone and missile threats prompting T...</td>\n",
       "      <td>The low cost of mass-producing tools for moder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>May 26, 2024</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td>Andrew MCKIRDY</td>\n",
       "      <td>Japan wrestles with legacy of graft-stained Ga...</td>\n",
       "      <td>Cost overruns, corruption and COVID-19 all tar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May 25, 2024</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td></td>\n",
       "      <td>Saury fading from Japan's dining tables amid p...</td>\n",
       "      <td>Catches of saury are mired in a prolonged slum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13195</th>\n",
       "      <td>Jan 31, 2020</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td></td>\n",
       "      <td>Number of foreign workers in Japan totals reco...</td>\n",
       "      <td>Chinese accounted for a quarter of the total w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13196</th>\n",
       "      <td>Jan 31, 2020</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td></td>\n",
       "      <td>Record 31.19 million foreign nationals entered...</td>\n",
       "      <td>The number of foreign nationals who entered Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13197</th>\n",
       "      <td>Jan 31, 2020</td>\n",
       "      <td>JAPAN, Crime &amp; Legal</td>\n",
       "      <td></td>\n",
       "      <td>Actress Erika Sawajiri pleads guilty to posses...</td>\n",
       "      <td>Actress Erika Sawajiri pleaded guilty Friday t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13198</th>\n",
       "      <td>Jan 31, 2020</td>\n",
       "      <td>JAPAN, Politics</td>\n",
       "      <td>Eric Johnston</td>\n",
       "      <td>Could growing tourism troubles unseat Kyoto's ...</td>\n",
       "      <td>Kyoto voters head to the polls Sunday to cast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13199</th>\n",
       "      <td>Jan 31, 2020</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td></td>\n",
       "      <td>Japan's METI recommends releasing Fukushima ra...</td>\n",
       "      <td>The industry ministry Friday recommended relea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date              division             author  \\\n",
       "0      May 26, 2024       JAPAN, Politics      Jesse Johnson   \n",
       "1      May 26, 2024       JAPAN, Politics                      \n",
       "2      May 26, 2024       JAPAN, ANALYSIS  Gabriel Dominguez   \n",
       "3      May 26, 2024                 JAPAN     Andrew MCKIRDY   \n",
       "4      May 25, 2024                 JAPAN                      \n",
       "...             ...                   ...                ...   \n",
       "13195  Jan 31, 2020                 JAPAN                      \n",
       "13196  Jan 31, 2020                 JAPAN                      \n",
       "13197  Jan 31, 2020  JAPAN, Crime & Legal                      \n",
       "13198  Jan 31, 2020       JAPAN, Politics      Eric Johnston   \n",
       "13199  Jan 31, 2020                 JAPAN                      \n",
       "\n",
       "                                                   title  \\\n",
       "0      Kishida meets China's Li and South Korea's Yoo...   \n",
       "1      Constitutional Democratic Party executives can...   \n",
       "2      Evolving drone and missile threats prompting T...   \n",
       "3      Japan wrestles with legacy of graft-stained Ga...   \n",
       "4      Saury fading from Japan's dining tables amid p...   \n",
       "...                                                  ...   \n",
       "13195  Number of foreign workers in Japan totals reco...   \n",
       "13196  Record 31.19 million foreign nationals entered...   \n",
       "13197  Actress Erika Sawajiri pleads guilty to posses...   \n",
       "13198  Could growing tourism troubles unseat Kyoto's ...   \n",
       "13199  Japan's METI recommends releasing Fukushima ra...   \n",
       "\n",
       "                                                 summary  \n",
       "0      The Japanese leader discussed improving ties w...  \n",
       "1      The CDP submitted a bill to the Lower House th...  \n",
       "2      The low cost of mass-producing tools for moder...  \n",
       "3      Cost overruns, corruption and COVID-19 all tar...  \n",
       "4      Catches of saury are mired in a prolonged slum...  \n",
       "...                                                  ...  \n",
       "13195  Chinese accounted for a quarter of the total w...  \n",
       "13196  The number of foreign nationals who entered Ja...  \n",
       "13197  Actress Erika Sawajiri pleaded guilty Friday t...  \n",
       "13198  Kyoto voters head to the polls Sunday to cast ...  \n",
       "13199  The industry ministry Friday recommended relea...  \n",
       "\n",
       "[13200 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_dataframes['japan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<span style=\"font-size: 26px;\">STEP 2 : COUNTING WORDS FOR EACH SECTION</span>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add summary and title into dictionary file\n",
    "def make_section_dictionary(sec):\n",
    "    #file\n",
    "    original_df = section_dataframes[sec]\n",
    "    #combine last 2 columns, 'title' & 'summary', into one list\n",
    "    combined_list = (original_df['title'] + ' ' + original_df['summary']).tolist()\n",
    "    combined_string = \" \".join(map(str,combined_list))\n",
    "    #clean combined list\n",
    "    combined_string_cleaned = combined_string.replace(\"'s\", \"\").replace(\"\\xa0\",\" \").replace(\"\\'\", \"\").replace(\"\\n\", \"\")\n",
    "    return combined_string_cleaned\n",
    "\n",
    "#For each words in result_word, leave only alphabets, then count the number of each words\n",
    "def word_count(counter, result_word):\n",
    "    if result_word:\n",
    "        result_word = re.sub('[^A-Za-z]+', '', result_word)\n",
    "        if result_word == None or result_word == '' or len(result_word) == 1: #remove Null values, or 1 character\n",
    "            return\n",
    "        else:\n",
    "            counter[result_word] += 1   #count frequency of each words\n",
    "\n",
    "#List of words that are used frequently, but not meaningful\n",
    "def stop_words_gen():\n",
    "    global stop_words\n",
    "    stop_words = stopwords.words('english')\n",
    "    custom =['one','two','three','since','say','said','says','also','could','would','may','many','like',\n",
    "             'still','get','even','back','make','week','made','come','comes','talks','must','used','see',\n",
    "             'th','set','around','take','second','among','go','big','good','long','way','monday','tuesday',\n",
    "             'wednesday','thursday','Friday','Saturday','Sunday','day','years','year','year-old','yearold',\n",
    "             'first','final','last']\n",
    "    stop_words.extend(custom)\n",
    "    stop_words.extend([word.capitalize() for word in stop_words])\n",
    "\n",
    "#clean each words and count them \n",
    "def clean_section_dic(text):\n",
    "    result = []\n",
    "    counter = defaultdict(int)\n",
    "    tokens = nltk.word_tokenize(text)   \n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            result.append(token)\n",
    "\n",
    "    for word in result:\n",
    "        word_count(counter, word)\n",
    "    sorted_counter = dict(sorted(counter.items(), key=lambda item: item[1], reverse=True))\n",
    "    df = pd.DataFrame(list(sorted_counter.items()), columns=['words', 'nums'])\n",
    "    df = df[df['nums']>100] #remove words that were used less than 100 times\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>japan</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>world</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asia-pacific</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  section\n",
       "0         japan      101\n",
       "1         world      102\n",
       "2  asia-pacific      103"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Give each section a unique id (number)\n",
    "section_nums = pd.DataFrame(enumerate(section_list,start=101),columns=['section','name'])\n",
    "section_nums = section_nums[['name','section']]\n",
    "section_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>words</th>\n",
       "      <th>nums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Japan</td>\n",
       "      <td>8382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>2733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>COVID</td>\n",
       "      <td>1877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>1694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>new</td>\n",
       "      <td>1687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>103</td>\n",
       "      <td>whether</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>103</td>\n",
       "      <td>came</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>103</td>\n",
       "      <td>worst</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>103</td>\n",
       "      <td>battle</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>103</td>\n",
       "      <td>lockdown</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1395 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      section     words  nums\n",
       "0         101     Japan  8382\n",
       "1         101     Tokyo  2733\n",
       "2         101     COVID  1877\n",
       "3         101  Japanese  1694\n",
       "4         101       new  1687\n",
       "...       ...       ...   ...\n",
       "1390      103   whether   102\n",
       "1391      103      came   101\n",
       "1392      103     worst   101\n",
       "1393      103    battle   101\n",
       "1394      103  lockdown   101\n",
       "\n",
       "[1395 rows x 3 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate all dataframes\n",
    "stop_words_gen()\n",
    "data_frame = []\n",
    "for i, section in enumerate(section_list, start=101):\n",
    "    sec_sentence = make_section_dictionary(section) # Concatenate 'title'&'summary' column from scraped articles\n",
    "    sec_word = clean_section_dic(sec_sentence)  # Clean the column and drop words used less than 100 times\n",
    "    sec_word.insert(0, 'section', i)  # Add section number column    \n",
    "    data_frame.append(sec_word) # Add counted tables to list\n",
    "final_df = pd.concat(data_frame, ignore_index=True)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to .csv file to use in tableau\n",
    "section_nums.to_csv('/Users/ronny/Code/Project/sections_num.csv', index=False)\n",
    "final_df.to_csv('/Users/ronny/Code/Project/finaltotalnumcount.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<span style=\"font-size: 26px;\">STEP 3: Author analysis</span>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_author_word(words, col):  # clean 'words', remove irrelevent words\n",
    "    if words:\n",
    "        words = re.sub('[^A-Za-z]+','', words)\n",
    "        if words == None or words in stop_words or words == '' or len(words) == 1:\n",
    "            return()\n",
    "        else:\n",
    "            col.append(words)\n",
    "\n",
    "def merge_title_summary(input_table,output_table):  # merge column 'title' and 'summary' to split into strings\n",
    "    title = input_table['title'][i] if pd.notna(input_table['title'][i]) else ''\n",
    "    summary = input_table['summary'][i] if pd.notna(input_table['summary'][i]) else ''\n",
    "    t = title.split()\n",
    "    s = summary.split()\n",
    "    merged_t_s = t + s\n",
    "    unclean_merge = []\n",
    "    for word in merged_t_s:\n",
    "        clean_author_word(word,unclean_merge)\n",
    "    output_table.append(unclean_merge)\n",
    "    return output_table\n",
    "\n",
    "def seperate_authors(input):    # Seperate authors, for single article with multiple authors\n",
    "    input['author'] = input['author'].str.split(',')\n",
    "    sepdf = input.explode('author')\n",
    "    sepdf['author'] = sepdf['author'].str.strip()\n",
    "    return sepdf\n",
    "\n",
    "def active_authors(input):  # remove authors who wrote less than 30 articles in total\n",
    "    author_article_count = input['author'].value_counts()\n",
    "    active_author = author_article_count[author_article_count >= 30].index  #author who wrote more than 30 articles\n",
    "    fin = input[input['author'].isin(active_author)].reset_index(drop=True)\n",
    "    fin['division'] = fin['division'].str.split(',')    #make division column as string to count division later\n",
    "    return fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>division</th>\n",
       "      <th>author</th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>May 26, 2024</td>\n",
       "      <td>[JAPAN,  Politics]</td>\n",
       "      <td>Jesse Johnson</td>\n",
       "      <td>[Kishida, meets, Chinas, Li, South, Koreas, Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May 26, 2024</td>\n",
       "      <td>[JAPAN,  ANALYSIS]</td>\n",
       "      <td>Gabriel Dominguez</td>\n",
       "      <td>[Evolving, drone, missile, threats, prompting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>May 24, 2024</td>\n",
       "      <td>[JAPAN]</td>\n",
       "      <td>Yukana Inoue</td>\n",
       "      <td>[Emergency, probe, Japan, Airlines, carried, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>May 24, 2024</td>\n",
       "      <td>[JAPAN,  Politics,  FOCUS]</td>\n",
       "      <td>Jesse Johnson</td>\n",
       "      <td>[JapanSouth, KoreaChina, trilateral, summit, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May 23, 2024</td>\n",
       "      <td>[JAPAN,  Science &amp; Health]</td>\n",
       "      <td>Yukana Inoue</td>\n",
       "      <td>[Health, ministry, panel, urges, consolidation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3458</th>\n",
       "      <td>Feb 2, 2020</td>\n",
       "      <td>[JAPAN,  Crime &amp; Legal]</td>\n",
       "      <td>Magdalena Osumi</td>\n",
       "      <td>[Justice, chief, Masako, Mori, defends, Japans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>Feb 1, 2020</td>\n",
       "      <td>[JAPAN,  Media,  MEDIA MIX]</td>\n",
       "      <td>Philip Brasor</td>\n",
       "      <td>[Shinjiro, Koizumis, paternity, leave, raises,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>Feb 1, 2020</td>\n",
       "      <td>[JAPAN,  Media,  BIG IN JAPAN]</td>\n",
       "      <td>Mark Schreiber</td>\n",
       "      <td>[Dispatches, front, line, Japans, retail, sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>Jan 31, 2020</td>\n",
       "      <td>[JAPAN]</td>\n",
       "      <td>Satoshi Sugiyama</td>\n",
       "      <td>[Japan, step, coronavirus, action, Abe, takes,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>Jan 31, 2020</td>\n",
       "      <td>[JAPAN,  Politics]</td>\n",
       "      <td>Eric Johnston</td>\n",
       "      <td>[growing, tourism, troubles, unseat, Kyotos, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3463 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date                        division             author  \\\n",
       "0     May 26, 2024              [JAPAN,  Politics]      Jesse Johnson   \n",
       "1     May 26, 2024              [JAPAN,  ANALYSIS]  Gabriel Dominguez   \n",
       "2     May 24, 2024                         [JAPAN]       Yukana Inoue   \n",
       "3     May 24, 2024      [JAPAN,  Politics,  FOCUS]      Jesse Johnson   \n",
       "4     May 23, 2024      [JAPAN,  Science & Health]       Yukana Inoue   \n",
       "...            ...                             ...                ...   \n",
       "3458   Feb 2, 2020         [JAPAN,  Crime & Legal]    Magdalena Osumi   \n",
       "3459   Feb 1, 2020     [JAPAN,  Media,  MEDIA MIX]      Philip Brasor   \n",
       "3460   Feb 1, 2020  [JAPAN,  Media,  BIG IN JAPAN]     Mark Schreiber   \n",
       "3461  Jan 31, 2020                         [JAPAN]   Satoshi Sugiyama   \n",
       "3462  Jan 31, 2020              [JAPAN,  Politics]      Eric Johnston   \n",
       "\n",
       "                                                 merged  \n",
       "0     [Kishida, meets, Chinas, Li, South, Koreas, Yo...  \n",
       "1     [Evolving, drone, missile, threats, prompting,...  \n",
       "2     [Emergency, probe, Japan, Airlines, carried, f...  \n",
       "3     [JapanSouth, KoreaChina, trilateral, summit, c...  \n",
       "4     [Health, ministry, panel, urges, consolidation...  \n",
       "...                                                 ...  \n",
       "3458  [Justice, chief, Masako, Mori, defends, Japans...  \n",
       "3459  [Shinjiro, Koizumis, paternity, leave, raises,...  \n",
       "3460  [Dispatches, front, line, Japans, retail, sect...  \n",
       "3461  [Japan, step, coronavirus, action, Abe, takes,...  \n",
       "3462  [growing, tourism, troubles, unseat, Kyotos, l...  \n",
       "\n",
       "[3463 rows x 4 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_csv = pd.DataFrame(section_dataframes['japan'])\n",
    "dropauthor = original_csv[original_csv['author'].str.strip() != ''].reset_index(drop=True)\n",
    "clean_merged = []\n",
    "\n",
    "for i in range(len(dropauthor)):\n",
    "    merge_title_summary(dropauthor,clean_merged)\n",
    "\n",
    "dropauthor['merged'] = clean_merged     #add column 'merged' and add merged title and summary\n",
    "author_merged = dropauthor.drop(columns=['title', 'summary'])   #drop column 'title' and 'summary'\n",
    "\n",
    "sepauthor = seperate_authors(author_merged)    #seperate authors into different rows\n",
    "\n",
    "#active author (authors who wrote more than 30 articles)\n",
    "activeauthor = active_authors(sepauthor)\n",
    "\n",
    "#change string into date \n",
    "for i in range(len(activeauthor['division'])):\n",
    "    activeauthor.loc[i ,'date'] = pd.to_datetime(activeauthor['date'][i]).strftime('%Y %b')   #to avoid chained assignment (in future case)\n",
    "    for j in range(len(activeauthor['division'][i])):\n",
    "        activeauthor['division'][i][j] = activeauthor['division'][i][j].strip().capitalize()\n",
    "activeauthor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_author_info(input,output):\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in input.iterrows():\n",
    "        author = row['author']\n",
    "        divisions = row['division']\n",
    "        date = row['date']\n",
    "        words = row['merged']\n",
    "\n",
    "        if author not in output:\n",
    "            output[author] = {\n",
    "                'author_article_division': defaultdict(int),\n",
    "                'author_used_words': defaultdict(int),\n",
    "                'author_article_date': defaultdict(int)\n",
    "            }\n",
    "\n",
    "        # Update division count\n",
    "        for division in divisions:\n",
    "            output[author]['author_article_division'][division] += 1\n",
    "\n",
    "        # Update word counts\n",
    "        for word in words:\n",
    "            output[author]['author_used_words'][word] += 1\n",
    "\n",
    "        # Update article date count\n",
    "        output[author]['author_article_date'][date] += 1\n",
    "        # Convert defaultdict to dict for final output and sort dates in reverse chronological order\n",
    "    \n",
    "    for author in output:\n",
    "        output[author]['author_article_division'] = dict(output[author]['author_article_division'])\n",
    "\n",
    "        output[author]['author_used_words'] = dict(\n",
    "            sorted(output[author]['author_used_words'].items(),\n",
    "            key=lambda x: x[1], # Define the order as the count of words, which is x[1]\n",
    "            reverse=True)[:20]  # Select top 20 words\n",
    "        )\n",
    "        output[author]['author_article_date'] = dict(\n",
    "            sorted(output[author]['author_article_date'].items(),\n",
    "            key=lambda x: x[0]) # Organize by date\n",
    "    )\n",
    "\n",
    "# Empty dictionary for storing author data\n",
    "authors_data = {}\n",
    "total_author_info(activeauthor,authors_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authors_info_table(input,author_category):  # Create dictionaries to save counted numbers\n",
    "    author_to_id = {author: id for id, author in enumerate(input.keys(), start=1)}\n",
    "    author_article_count = {author: sum(data['author_article_date'].values()) for author, data in input.items()}\n",
    "    rows_author = [{'Author ID': author_id,'Author Category' : author_category ,'Author': author, 'Article Count': author_article_count[author]} for author, author_id in author_to_id.items()]\n",
    "\n",
    "    # Create DataFrames for each aspect\n",
    "    rows_date = []\n",
    "    rows_division = []\n",
    "    rows_words = []\n",
    "\n",
    "    # Add Author information into each DataFrames\n",
    "    for author, data in input.items():\n",
    "        author_id = author_to_id[author]    # Consider Author as author id\n",
    "        for date, date_count in data['author_article_date'].items():    # Count number of articles written in date \n",
    "            rows_date.append({\n",
    "                'Author ID': author_id,\n",
    "                'Date': date,\n",
    "                'Date Count': date_count\n",
    "            })\n",
    "        for division, division_count in data['author_article_division'].items():    # Count number of articles written in each division\n",
    "            rows_division.append({\n",
    "                'Author ID': author_id,\n",
    "                'Division': division,\n",
    "                'Division Count': division_count\n",
    "            })\n",
    "        for word, word_count in data['author_used_words'].items():  # Count used words for each authors \n",
    "            rows_words.append({\n",
    "                'Author ID': author_id,\n",
    "                'Word': word,\n",
    "                'Word Count': word_count\n",
    "            })\n",
    "    return rows_author, rows_date, rows_division, rows_words\n",
    "\n",
    "author_table, author_date, author_division, author_words = authors_info_table(authors_data,1001) #1001 is category id of 'japan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Date Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015 Dec</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 Apr</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 Aug</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 Dec</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 Feb</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>22</td>\n",
       "      <td>2022 Mar</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>22</td>\n",
       "      <td>2022 May</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>22</td>\n",
       "      <td>2023 Apr</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>22</td>\n",
       "      <td>2023 Mar</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>22</td>\n",
       "      <td>2023 May</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>736 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Author ID      Date  Date Count\n",
       "0            1  2015 Dec           1\n",
       "1            1  2016 Apr           9\n",
       "2            1  2016 Aug          12\n",
       "3            1  2016 Dec           9\n",
       "4            1  2016 Feb           2\n",
       "..         ...       ...         ...\n",
       "731         22  2022 Mar           2\n",
       "732         22  2022 May           3\n",
       "733         22  2023 Apr           2\n",
       "734         22  2023 Mar           4\n",
       "735         22  2023 May           1\n",
       "\n",
       "[736 rows x 3 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change into DataFrames\n",
    "df_author = pd.DataFrame(author_table)\n",
    "df_date = pd.DataFrame(author_date)\n",
    "df_division = pd.DataFrame(author_division)\n",
    "df_words = pd.DataFrame(author_words)\n",
    "df_author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<span style=\"font-size: 26px;\">Convert Table into .csv file for Analysis</span>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create normalized tables for each section\n",
    "for sec_num,section in enumerate(section_list,start=1001):\n",
    "    original_csv = pd.DataFrame(section_dataframes[section])\n",
    "    dropauthor = original_csv[original_csv['author'].str.strip() != ''].reset_index(drop=True)\n",
    "    clean_merged = []\n",
    "\n",
    "    for i in range(len(dropauthor)):\n",
    "        merge_title_summary(dropauthor,clean_merged)\n",
    "\n",
    "    dropauthor['merged'] = clean_merged     #add column 'merged' and add merged title and summary\n",
    "    author_merged = dropauthor.drop(columns=['title', 'summary'])   #drop column 'title' and 'summary'\n",
    "\n",
    "    sepauthor = seperate_authors(author_merged)    #seperate authors into different rows\n",
    "\n",
    "    #active author (authors who wrote more than 30 articles)\n",
    "    activeauthor = active_authors(sepauthor)\n",
    "\n",
    "    #change string into date \n",
    "    for i in range(len(activeauthor['division'])):\n",
    "        activeauthor.loc[i ,'date'] = pd.to_datetime(activeauthor['date'][i]).strftime('%Y %b')   #to avoid chained assignment (in future case)\n",
    "        for j in range(len(activeauthor['division'][i])):\n",
    "            activeauthor['division'][i][j] = activeauthor['division'][i][j].strip().capitalize()\n",
    "\n",
    "    authors_data = {}\n",
    "    total_author_info(activeauthor,authors_data)\n",
    "    author_table, author_date, author_division, author_words = authors_info_table(authors_data,sec_num)\n",
    "    \n",
    "    df_author = pd.DataFrame(author_table)\n",
    "    df_date = pd.DataFrame(author_date)\n",
    "    df_division = pd.DataFrame(author_division)\n",
    "    df_words = pd.DataFrame(author_words)\n",
    "\n",
    "    df_author.to_csv(f'/Users/ronny/Code/Project/newauthor/{section}-authorinfo.csv', index=False)\n",
    "    df_date.to_csv(f'/Users/ronny/Code/Project/newauthor/{section}-date.csv', index=False)\n",
    "    df_division.to_csv(f'/Users/ronny/Code/Project/newauthor/{section}-division.csv', index=False)\n",
    "    df_words.to_csv(f'/Users/ronny/Code/Project/newauthor/{section}-words.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
